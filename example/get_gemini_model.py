from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage , SystemMessage
from langchain_core.prompts import ChatPromptTemplate 
from dotenv import load_dotenv
import re
import requests
import json
import os
load_dotenv()

def fetch_gemini_models_and_save():
    """
    Google Gemini APIì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ì„ HTTP ìš”ì²­ìœ¼ë¡œ ê°€ì ¸ì™€ì„œ JSON íŒŒì¼ë¡œ ì €ì¥
    """
    # í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
    api_key = os.getenv('GOOGLE_API_KEY')
    if not api_key:
        print("GOOGLE_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None
    
    # Gemini API ì—”ë“œí¬ì¸íŠ¸
    url = f"https://generativelanguage.googleapis.com/v1beta/models?key={api_key}"
    
    try:
        # HTTP GET ìš”ì²­ ë³´ë‚´ê¸°
        response = requests.get(url)
        response.raise_for_status()  # HTTP ì—ëŸ¬ê°€ ìˆìœ¼ë©´ ì˜ˆì™¸ ë°œìƒ
        
        # JSON ì‘ë‹µ íŒŒì‹±
        models_data = response.json()
        
        # ëª¨ë¸ëª…ë§Œ ì¶”ì¶œí•˜ê¸°
        model_names = []
        real_model_names = []
        
        if 'models' in models_data:
            for model in models_data['models']:
                model_names.append(model['name'])
                # 'models/' ì ‘ë‘ì‚¬ ì œê±°
                real_name = model['name'].split('/')[-1]
                real_model_names.append(real_name)
        
        # ê²°ê³¼ë¥¼ ë‹¤ì–‘í•œ í˜•íƒœë¡œ ì €ì¥
        result = {
            "timestamp": requests.utils.default_headers()['User-Agent'],
            "total_models": len(model_names),
            "full_response": models_data,
            "model_names_with_prefix": model_names,
            "model_names_only": real_model_names,
            "model_names_comma_separated": ",".join(real_model_names)
        }
        
        # JSON íŒŒì¼ë¡œ ì €ì¥
        output_file = "gemini_models.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… ëª¨ë¸ ëª©ë¡ì´ {output_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print(f"ğŸ“Š ì´ {len(model_names)}ê°œì˜ ëª¨ë¸ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ì£¼ìš” ëª¨ë¸ë“¤ ì¶œë ¥
        print("\nğŸ”¥ ì£¼ìš” ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ë“¤:")
        for name in real_model_names[:10]:  # ì²˜ìŒ 10ê°œë§Œ ì¶œë ¥
            print(f"  - {name}")
        
        if len(real_model_names) > 10:
            print(f"  ... ë° {len(real_model_names) - 10}ê°œ ë”")
            
        return result
        
    except requests.exceptions.RequestException as e:
        print(f"âŒ HTTP ìš”ì²­ ì˜¤ë¥˜: {e}")
        return None
    except json.JSONDecodeError as e:
        print(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        return None
    except Exception as e:
        print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        return None


if __name__ == "__main__":
    print("ğŸš€ Gemini ëª¨ë¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì‹œì‘...")
    
    # Gemini APIì—ì„œ ëª¨ë¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    gemini_result = fetch_gemini_models_and_save()
    
    print("\n" + "="*50)
    

    
